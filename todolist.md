> try if we can batch job faster(or it will meet time limit error)/ or just gviving more time when using the  
> doing zero shot one time for each dataset (extra file)

> extra places: https://github.com/mlabonne/llm-datasets (with very big file sizes)

# dataset waited to be used
1. https://www.tensorflow.org/datasets/catalog/math_dataset
2. [V]https://huggingface.co/datasets/allenai/art (too big)
3. [V]https://huggingface.co/datasets/textmachinelab/quail
4. [V]https://huggingface.co/datasets/openlifescienceai/medmcqa (too big)
5. [V]https://huggingface.co/datasets/openai/gsm8k
6. https://huggingface.co/datasets/TsinghuaC3I/MedXpertQA

